import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.models import ResNet50_Weights
from PIL import Image
import torch.nn.functional as F
from pathlib import Path
from .emotion_labels import DOG_EMOTIONS, EMOTION_KOREAN

class DogEmotionModel(nn.Module):
    """
    ê°•ì•„ì§€ ê°ì • ë¶„ë¥˜ë¥¼ ìœ„í•œ ResNet50 ê¸°ë°˜ ëª¨ë¸
    Transfer Learning ì ìš©
    """
    
    def __init__(self, num_classes=4, pretrained=True, dropout_rate=0.3):
        """
        Args:
            num_classes (int): ê°ì • í´ë˜ìŠ¤ ìˆ˜ (ê¸°ë³¸ê°’: 4 - angry, happy, relaxed, sad)
            pretrained (bool): ImageNet ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€
            dropout_rate (float): Dropout ë¹„ìœ¨
        """
        super(DogEmotionModel, self).__init__()
        
        self.num_classes = num_classes
        
        # ResNet50 ë°±ë³¸ ëª¨ë¸ ë¡œë“œ
        if pretrained:
            weights = ResNet50_Weights.IMAGENET1K_V2
            self.backbone = models.resnet50(weights=weights)
        else:
            self.backbone = models.resnet50(weights=None)
        
        # ì›ë³¸ ë¶„ë¥˜ í—¤ë“œ ì œê±°
        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])  # avgpoolê¹Œì§€ë§Œ
        
        # ì»¤ìŠ¤í…€ ë¶„ë¥˜ í—¤ë“œ êµ¬ì„±
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling
            nn.Flatten(),
            nn.Dropout(dropout_rate),
            nn.Linear(2048, 512),          # ì²« ë²ˆì§¸ FC ë ˆì´ì–´
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(512),
            nn.Dropout(dropout_rate),
            nn.Linear(512, 256),           # ë‘ ë²ˆì§¸ FC ë ˆì´ì–´
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(256),
            nn.Dropout(dropout_rate),
            nn.Linear(256, num_classes)    # ìµœì¢… ë¶„ë¥˜ ë ˆì´ì–´
        )
        
        # ê°ì • ë¼ë²¨ ë§¤í•‘
        self.emotion_labels = ['angry', 'happy', 'relaxed', 'sad']
        self.emotion_to_idx = {emotion: idx for idx, emotion in enumerate(self.emotion_labels)}
        self.idx_to_emotion = {idx: emotion for emotion, idx in self.emotion_to_idx.items()}
    
    def forward(self, x):
        """
        ìˆœì „íŒŒ í•¨ìˆ˜
        
        Args:
            x (torch.Tensor): ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ (N, 3, 224, 224)
            
        Returns:
            torch.Tensor: í´ë˜ìŠ¤ë³„ ë¡œì§“ (N, num_classes)
        """
        # ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•œ íŠ¹ì„± ì¶”ì¶œ
        features = self.backbone(x)
        
        # ë¶„ë¥˜ í—¤ë“œë¥¼ í†µí•œ ìµœì¢… ì˜ˆì¸¡
        logits = self.classifier(features)
        
        return logits

class DogEmotionClassifier:
    def __init__(self, model_path=None):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # í•™ìŠµëœ ëª¨ë¸ ìƒì„±
        self.model = DogEmotionModel(
            num_classes=4,
            pretrained=True,
            dropout_rate=0.3
        )
        
        # í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
        if model_path is None:
            # ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
            model_path = Path(__file__).parent / "checkpoints_finetune" / "best_model.pth"
        
        if Path(model_path).exists():
            try:
                checkpoint = torch.load(model_path, map_location=self.device)
                # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ìƒíƒœë§Œ ë¡œë“œ
                if 'model_state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                    print(f"âœ… í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ: {model_path}")
                else:
                    self.model.load_state_dict(checkpoint)
                    print(f"âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ: {model_path}")
            except Exception as e:
                print(f"âš ï¸ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("ğŸ”§ ì‚¬ì „ í•™ìŠµëœ ResNet50 ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            print("ğŸ”§ ì‚¬ì „ í•™ìŠµëœ ResNet50 ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        self.model.eval()
        self.model.to(self.device)
        
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
    
    def predict(self, image_bytes):
        image = Image.open(image_bytes).convert('RGB')
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(input_tensor)
            probabilities = F.softmax(outputs, dim=1)
            
        # Get top prediction
        top_prob, top_idx = torch.max(probabilities, 1)
        
        emotion_idx = top_idx.item()
        confidence = top_prob.item() * 100
        
        emotion_en = DOG_EMOTIONS[emotion_idx]
        emotion_kr = EMOTION_KOREAN[emotion_en]
        
        # ëª¨ë“  ê°ì •ì˜ í™•ë¥  ê³„ì‚° (100%ê°€ ë˜ë„ë¡ ì •ê·œí™”)
        all_probabilities = probabilities[0]
        emotions_distribution = {}
        for idx, emotion in DOG_EMOTIONS.items():
            prob = all_probabilities[idx].item() * 100
            emotions_distribution[emotion] = round(prob, 1)
        
        return {
            "emotion": emotion_en,
            "emotionKorean": emotion_kr,
            "confidence": round(confidence, 1),
            "emotions": emotions_distribution
        }