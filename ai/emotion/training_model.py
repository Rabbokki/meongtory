"""
ê°•ì•„ì§€ ê°ì • ë¶„ë¥˜ë¥¼ ìœ„í•œ ê°œì„ ëœ PyTorch ëª¨ë¸
Transfer Learningì„ í™œìš©í•œ ResNet50 ê¸°ë°˜ ëª¨ë¸
"""

import torch
import torch.nn as nn
import torchvision.models as models
from torchvision.models import ResNet50_Weights
import torch.nn.functional as F
import sys
import io

# Windows ì½˜ì†”ì—ì„œ í•œê¸€ ì¶œë ¥ (ê¸°ë³¸ ì¸ì½”ë”© ì‚¬ìš©)

class DogEmotionModel(nn.Module):
    """
    ê°•ì•„ì§€ ê°ì • ë¶„ë¥˜ë¥¼ ìœ„í•œ ResNet50 ê¸°ë°˜ ëª¨ë¸
    Transfer Learning ì ìš©
    """
    
    def __init__(self, num_classes=4, pretrained=True, dropout_rate=0.5):
        """
        Args:
            num_classes (int): ê°ì • í´ë˜ìŠ¤ ìˆ˜ (ê¸°ë³¸ê°’: 4 - angry, happy, relaxed, sad)
            pretrained (bool): ImageNet ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€
            dropout_rate (float): Dropout ë¹„ìœ¨
        """
        super(DogEmotionModel, self).__init__()
        
        self.num_classes = num_classes
        
        # ResNet50 ë°±ë³¸ ëª¨ë¸ ë¡œë“œ
        if pretrained:
            weights = ResNet50_Weights.IMAGENET1K_V2
            self.backbone = models.resnet50(weights=weights)
            print("âœ… ImageNet ì‚¬ì „ í•™ìŠµëœ ResNet50 ê°€ì¤‘ì¹˜ ë¡œë“œë¨")
        else:
            self.backbone = models.resnet50(weights=None)
            print("ğŸ”§ ë¬´ì‘ìœ„ ì´ˆê¸°í™”ëœ ResNet50 ëª¨ë¸ ìƒì„±ë¨")
        
        # ì›ë³¸ ë¶„ë¥˜ í—¤ë“œ ì œê±°
        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])  # avgpoolê¹Œì§€ë§Œ
        
        # ì»¤ìŠ¤í…€ ë¶„ë¥˜ í—¤ë“œ êµ¬ì„±
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling
            nn.Flatten(),
            nn.Dropout(dropout_rate),
            nn.Linear(2048, 512),          # ì²« ë²ˆì§¸ FC ë ˆì´ì–´
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(512),
            nn.Dropout(dropout_rate),
            nn.Linear(512, 256),           # ë‘ ë²ˆì§¸ FC ë ˆì´ì–´
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(256),
            nn.Dropout(dropout_rate),
            nn.Linear(256, num_classes)    # ìµœì¢… ë¶„ë¥˜ ë ˆì´ì–´
        )
        
        # ê°ì • ë¼ë²¨ ë§¤í•‘
        self.emotion_labels = ['angry', 'happy', 'relaxed', 'sad']
        self.emotion_to_idx = {emotion: idx for idx, emotion in enumerate(self.emotion_labels)}
        self.idx_to_emotion = {idx: emotion for emotion, idx in self.emotion_to_idx.items()}
        
        print(f"ğŸ­ ê°ì • í´ë˜ìŠ¤ ë§¤í•‘: {self.emotion_to_idx}")
    
    def forward(self, x):
        """
        ìˆœì „íŒŒ í•¨ìˆ˜
        
        Args:
            x (torch.Tensor): ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ (N, 3, 224, 224)
            
        Returns:
            torch.Tensor: í´ë˜ìŠ¤ë³„ ë¡œì§“ (N, num_classes)
        """
        # ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•œ íŠ¹ì„± ì¶”ì¶œ
        features = self.backbone(x)
        
        # ë¶„ë¥˜ í—¤ë“œë¥¼ í†µí•œ ìµœì¢… ì˜ˆì¸¡
        logits = self.classifier(features)
        
        return logits
    
    def predict_emotion(self, x, return_probabilities=False):
        """
        ê°ì • ì˜ˆì¸¡ í•¨ìˆ˜
        
        Args:
            x (torch.Tensor): ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ
            return_probabilities (bool): í™•ë¥  ë°˜í™˜ ì—¬ë¶€
            
        Returns:
            dict: ì˜ˆì¸¡ ê²°ê³¼
        """
        self.eval()
        with torch.no_grad():
            logits = self(x)
            probabilities = F.softmax(logits, dim=1)
            
            # ìµœê³  í™•ë¥ ì˜ ê°ì • ì˜ˆì¸¡
            top_prob, top_idx = torch.max(probabilities, dim=1)
            
            # ë°°ì¹˜ë³„ ê²°ê³¼ ì²˜ë¦¬
            results = []
            for i in range(len(top_idx)):
                emotion_idx = top_idx[i].item()
                confidence = top_prob[i].item()
                emotion_name = self.idx_to_emotion[emotion_idx]
                
                result = {
                    'emotion': emotion_name,
                    'confidence': confidence,
                    'emotion_idx': emotion_idx
                }
                
                if return_probabilities:
                    result['probabilities'] = {
                        self.idx_to_emotion[idx]: prob.item() 
                        for idx, prob in enumerate(probabilities[i])
                    }
                
                results.append(result)
        
        return results[0] if len(results) == 1 else results
    
    def freeze_backbone(self):
        """ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê³ ì •í•©ë‹ˆë‹¤ (ë¶„ë¥˜ í—¤ë“œë§Œ í•™ìŠµ)"""
        for param in self.backbone.parameters():
            param.requires_grad = False
        print("ğŸ”’ ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ ê°€ì¤‘ì¹˜ê°€ ê³ ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ë¥˜ í—¤ë“œë§Œ í•™ìŠµë©ë‹ˆë‹¤.")
    
    def unfreeze_backbone(self):
        """ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ë¥¼ í•´ì œí•©ë‹ˆë‹¤ (ì „ì²´ ëª¨ë¸ í•™ìŠµ)"""
        for param in self.backbone.parameters():
            param.requires_grad = True
        print("ğŸ”“ ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ ê°€ì¤‘ì¹˜ê°€ í•´ì œë˜ì—ˆìŠµë‹ˆë‹¤. ì „ì²´ ëª¨ë¸ì´ í•™ìŠµë©ë‹ˆë‹¤.")
    
    def get_trainable_params(self):
        """í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in self.parameters())
        
        print(f"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„°:")
        print(f"   - í•™ìŠµ ê°€ëŠ¥: {trainable_params:,}ê°œ")
        print(f"   - ì „ì²´: {total_params:,}ê°œ")
        print(f"   - ë¹„ìœ¨: {trainable_params/total_params*100:.1f}%")
        
        return trainable_params, total_params

def create_model(num_classes=4, pretrained=True, dropout_rate=0.5, freeze_backbone=True):
    """
    ëª¨ë¸ ìƒì„± í—¬í¼ í•¨ìˆ˜
    
    Args:
        num_classes (int): ê°ì • í´ë˜ìŠ¤ ìˆ˜
        pretrained (bool): ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€
        dropout_rate (float): Dropout ë¹„ìœ¨
        freeze_backbone (bool): ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ ê³ ì • ì—¬ë¶€
        
    Returns:
        DogEmotionModel: ìƒì„±ëœ ëª¨ë¸
    """
    model = DogEmotionModel(
        num_classes=num_classes,
        pretrained=pretrained,
        dropout_rate=dropout_rate
    )
    
    if freeze_backbone:
        model.freeze_backbone()
    
    model.get_trainable_params()
    
    return model

def test_model():
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ëª¨ë¸ ìƒì„±
    model = create_model(
        num_classes=4,
        pretrained=True,
        freeze_backbone=True,
        dropout_rate=0.5
    )
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥ ìƒì„± (ë°°ì¹˜ í¬ê¸° 2)
    batch_size = 2
    test_input = torch.randn(batch_size, 3, 224, 224)
    
    print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì…ë ¥ í˜•íƒœ: {test_input.shape}")
    
    # ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸
    model.eval()
    with torch.no_grad():
        # ë¡œì§“ ì¶œë ¥
        logits = model(test_input)
        print(f"ğŸ“Š ë¡œì§“ ì¶œë ¥ í˜•íƒœ: {logits.shape}")
        print(f"ğŸ“Š ë¡œì§“ ê°’ ë²”ìœ„: [{logits.min():.3f}, {logits.max():.3f}]")
        
        # ê°ì • ì˜ˆì¸¡
        predictions = model.predict_emotion(test_input, return_probabilities=True)
        
        print(f"\nğŸ­ ì˜ˆì¸¡ ê²°ê³¼:")
        for i, pred in enumerate(predictions):
            print(f"   ìƒ˜í”Œ {i+1}: {pred['emotion']} (ì‹ ë¢°ë„: {pred['confidence']:.3f})")
            print(f"   í™•ë¥  ë¶„í¬: {pred['probabilities']}")
    
    print("\nâœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return model

if __name__ == "__main__":
    # ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    model = test_model()
    
    print("\nğŸ‰ ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ğŸš€ ì´ì œ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")