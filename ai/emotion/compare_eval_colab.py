import os
from pathlib import Path
from typing import Dict, Tuple, List

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.models import ResNet50_Weights
from torchvision import datasets
from torch.utils.data import DataLoader

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    accuracy_score,
    f1_score,
)
import sys


# =========================
# ì‚¬ìš©ì ì„¤ì • (Colab í™˜ê²½ ê¸°ì¤€)
# =========================
# Colabì—ì„œëŠ” ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
VAL_DIR = "/content/mt/ai/emotion/val"
ORIGINAL_MODEL_PATH = "/content/mt/ai/emotion/checkpoints_finetune/best_model_original.pth"
RETRAINED_MODEL_PATH = "/content/mt/ai/emotion/checkpoints_finetune/best_model.pth"


# =========================
# ë¼ë²¨ ì •ì˜ (model.pyì™€ ë™ì¼ ìˆœì„œ)
# =========================
DOG_EMOTIONS = {
    0: "angry",
    1: "happy",
    2: "relaxed",
    3: "sad",
}
EMOTION_KOREAN = {
    "angry": "í™”ë‚¨",
    "happy": "í–‰ë³µ",
    "relaxed": "í¸ì•ˆ",
    "sad": "ìŠ¬í””",
}


# =========================
# model.pyì˜ DogEmotionModel êµ¬ì¡° ë³µì œ
# =========================
class DogEmotionModel(nn.Module):
    """
    ê°•ì•„ì§€ ê°ì • ë¶„ë¥˜ë¥¼ ìœ„í•œ ResNet50 ê¸°ë°˜ ëª¨ë¸ (Transfer Learning)
    """

    def __init__(self, num_classes: int = 4, pretrained: bool = True, dropout_rate: float = 0.3):
        super(DogEmotionModel, self).__init__()
        self.num_classes = num_classes

        if pretrained:
            weights = ResNet50_Weights.IMAGENET1K_V2
            backbone = models.resnet50(weights=weights)
        else:
            backbone = models.resnet50(weights=None)

        # avgpoolê¹Œì§€ ë°±ë³¸ ì¶”ì¶œ
        self.backbone = nn.Sequential(*list(backbone.children())[:-1])

        # ì»¤ìŠ¤í…€ ë¶„ë¥˜ í—¤ë“œ
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Dropout(dropout_rate),
            nn.Linear(2048, 512),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(512),
            nn.Dropout(dropout_rate),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(256),
            nn.Dropout(dropout_rate),
            nn.Linear(256, num_classes),
        )

        self.emotion_labels = ['angry', 'happy', 'relaxed', 'sad']
        self.emotion_to_idx = {emotion: idx for idx, emotion in enumerate(self.emotion_labels)}
        self.idx_to_emotion = {idx: emotion for emotion, idx in self.emotion_to_idx.items()}

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        features = self.backbone(x)
        logits = self.classifier(features)
        return logits


# =========================
# Transform (model.pyì™€ ë™ì¼)
# =========================
val_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])


# =========================
# ìœ í‹¸ í•¨ìˆ˜
# =========================
def load_finetuned_weights(model: nn.Module, checkpoint_path: str, device: torch.device) -> None:
    assert os.path.isfile(checkpoint_path), f"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}"
    ckpt = torch.load(checkpoint_path, map_location=device)
    if isinstance(ckpt, dict) and "model_state_dict" in ckpt:
        model.load_state_dict(ckpt["model_state_dict"])
    else:
        model.load_state_dict(ckpt)


@torch.inference_mode()
def evaluate_model(model: nn.Module, loader: DataLoader, device: torch.device) -> Tuple[float, np.ndarray, np.ndarray]:
    model.eval()
    y_true: List[int] = []
    y_pred: List[int] = []

    for images, labels in loader:
        images = images.to(device, non_blocking=True)
        logits = model(images)
        probs = F.softmax(logits, dim=1)
        preds = probs.argmax(dim=1).cpu().numpy()
        y_pred.extend(list(preds))
        y_true.extend(list(labels.numpy()))

    acc = accuracy_score(y_true, y_pred)
    return acc, np.array(y_true), np.array(y_pred)


def plot_accuracy_compare(acc_init: float, acc_original: float, acc_retrained: float) -> None:
    plt.figure(figsize=(8, 5))
    methods = ["Initial model", "Original fine-tuned", "Retrained model"]
    values = [acc_init * 100, acc_original * 100, acc_retrained * 100]
    bars = plt.bar(methods, values, color=["#9999ff", "#66cc99", "#ff9966"])
    plt.ylabel("Accuracy (%)")
    plt.title("Overall Accuracy Comparison (3-Model)")
    for bar, val in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width()/2.0, bar.get_height() + 0.5, f"{val:.1f}%", ha='center', va='bottom')
    plt.ylim(0, 100)
    plt.grid(axis="y", alpha=0.2)
    plt.xticks(rotation=15)
    plt.tight_layout()
    plt.show()


def plot_confusion_matrices(y_true_init, y_pred_init, y_true_orig, y_pred_orig, y_true_retrained, y_pred_retrained, class_names: List[str]) -> None:
    cm_init = confusion_matrix(y_true_init, y_pred_init, labels=list(range(len(class_names))))
    cm_orig = confusion_matrix(y_true_orig, y_pred_orig, labels=list(range(len(class_names))))
    cm_retrained = confusion_matrix(y_true_retrained, y_pred_retrained, labels=list(range(len(class_names))))

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    
    sns.heatmap(cm_init, annot=True, fmt="d", cmap="Blues", ax=axes[0],
                xticklabels=class_names, yticklabels=class_names)
    axes[0].set_title("Initial Model")
    axes[0].set_xlabel("Predicted")
    axes[0].set_ylabel("Actual")

    sns.heatmap(cm_orig, annot=True, fmt="d", cmap="Greens", ax=axes[1],
                xticklabels=class_names, yticklabels=class_names)
    axes[1].set_title("Original Fine-tuned")
    axes[1].set_xlabel("Predicted")
    axes[1].set_ylabel("Actual")

    sns.heatmap(cm_retrained, annot=True, fmt="d", cmap="Oranges", ax=axes[2],
                xticklabels=class_names, yticklabels=class_names)
    axes[2].set_title("Retrained Model")
    axes[2].set_xlabel("Predicted")
    axes[2].set_ylabel("Actual")

    plt.tight_layout()
    plt.show()


def plot_per_class_f1(y_true_init, y_pred_init, y_true_orig, y_pred_orig, y_true_retrained, y_pred_retrained, class_names: List[str]) -> None:
    f1_init = f1_score(y_true_init, y_pred_init, average=None, labels=list(range(len(class_names))))
    f1_orig = f1_score(y_true_orig, y_pred_orig, average=None, labels=list(range(len(class_names))))
    f1_retrained = f1_score(y_true_retrained, y_pred_retrained, average=None, labels=list(range(len(class_names))))

    x = np.arange(len(class_names))

    plt.figure(figsize=(10, 5))
    plt.plot(x, f1_init, marker='o', linewidth=2.0, color="#5967ff", label="Initial")
    plt.plot(x, f1_orig, marker='s', linewidth=2.0, color="#1abc9c", label="Original Fine-tuned")
    plt.plot(x, f1_retrained, marker='^', linewidth=2.0, color="#ff7f0e", label="Retrained")
    plt.xticks(x, class_names)
    plt.ylim(0, 1.0)
    plt.ylabel("F1-score")
    plt.title("Per-class F1-score Comparison (3-Model)")
    plt.legend()
    plt.grid(axis="y", alpha=0.2)
    plt.tight_layout()
    plt.show()


def print_reports(y_true_init, y_pred_init, y_true_orig, y_pred_orig, y_true_retrained, y_pred_retrained, class_names: List[str]) -> None:
    print("=== Initial Model Classification Report ===")
    print(classification_report(y_true_init, y_pred_init, target_names=class_names, digits=3))
    print("\n=== Original Fine-tuned Model Classification Report ===")
    print(classification_report(y_true_orig, y_pred_orig, target_names=class_names, digits=3))
    print("\n=== Retrained Model Classification Report ===")
    print(classification_report(y_true_retrained, y_pred_retrained, target_names=class_names, digits=3))




def main() -> None:
    # GPU ì „ìš© ì„¤ì • (Colab)
    assert torch.cuda.is_available(), "Colab ëŸ°íƒ€ì„ì—ì„œ GPUë¥¼ ì¼œì„¸ìš”: Runtime -> Change runtime type -> GPU"
    device = torch.device("cuda")
    torch.backends.cudnn.benchmark = True
    print("Device:", device)

    # ë°ì´í„°ì…‹ & ë¡œë”
    assert os.path.isdir(VAL_DIR), f"ê²€ì¦ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {VAL_DIR}"
    val_dataset = datasets.ImageFolder(root=VAL_DIR, transform=val_transform)
    print("ImageFolder class_to_idx:", val_dataset.class_to_idx)

    val_loader = DataLoader(
        val_dataset,
        batch_size=32,
        shuffle=False,
        num_workers=2,
        pin_memory=True,
    )

    # ëª¨ë¸ ì¤€ë¹„ (3ê°œ ëª¨ë¸)
    init_model = DogEmotionModel(num_classes=4, pretrained=True, dropout_rate=0.3).to(device)
    original_model = DogEmotionModel(num_classes=4, pretrained=True, dropout_rate=0.3).to(device)
    retrained_model = DogEmotionModel(num_classes=4, pretrained=True, dropout_rate=0.3).to(device)

    # ì›ë³¸ íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ
    if os.path.isfile(ORIGINAL_MODEL_PATH):
        load_finetuned_weights(original_model, ORIGINAL_MODEL_PATH, device)
        print(f"âœ… ì›ë³¸ íŒŒì¸íŠœë‹ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ: {ORIGINAL_MODEL_PATH}")
    else:
        raise FileNotFoundError(f"ì›ë³¸ íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ORIGINAL_MODEL_PATH}")
    
    # ì¬í•™ìŠµ ëª¨ë¸ ë¡œë“œ
    if os.path.isfile(RETRAINED_MODEL_PATH):
        load_finetuned_weights(retrained_model, RETRAINED_MODEL_PATH, device)
        print(f"âœ… ì¬í•™ìŠµ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ: {RETRAINED_MODEL_PATH}")
    else:
        raise FileNotFoundError(f"ì¬í•™ìŠµ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {RETRAINED_MODEL_PATH}")

    # í‰ê°€ (3ê°œ ëª¨ë¸)
    print("ğŸ” ì´ˆê¸° ëª¨ë¸(ì‚¬ì „í•™ìŠµë§Œ) í‰ê°€ ì¤‘...")
    acc_init, y_true_init, y_pred_init = evaluate_model(init_model, val_loader, device)
    
    print("ğŸ” ì›ë³¸ íŒŒì¸íŠœë‹ ëª¨ë¸ í‰ê°€ ì¤‘...")
    acc_orig, y_true_orig, y_pred_orig = evaluate_model(original_model, val_loader, device)
    
    print("ğŸ” ì¬í•™ìŠµ ëª¨ë¸ í‰ê°€ ì¤‘...")
    acc_retrained, y_true_retrained, y_pred_retrained = evaluate_model(retrained_model, val_loader, device)

    print("\n" + "="*60)
    print("ğŸ“Š 3-ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
    print("="*60)
    print(f"ğŸ“Œ ì´ˆê¸° ëª¨ë¸ ì •í™•ë„:        {acc_init*100:.2f}%")
    print(f"ğŸ¯ ì›ë³¸ íŒŒì¸íŠœë‹ ì •í™•ë„:    {acc_orig*100:.2f}%")
    print(f"ğŸš€ ì¬í•™ìŠµ ëª¨ë¸ ì •í™•ë„:      {acc_retrained*100:.2f}%")
    print("="*60)
    print(f"ğŸ“ˆ ì´ˆê¸° â†’ ì›ë³¸ ê°œì„ :       +{(acc_orig-acc_init)*100:.2f}%p")
    print(f"ğŸ”¥ ì›ë³¸ â†’ ì¬í•™ìŠµ ê°œì„ :     +{(acc_retrained-acc_orig)*100:.2f}%p")
    print(f"â­ ì „ì²´ ê°œì„  (ì´ˆê¸°â†’ì¬í•™ìŠµ): +{(acc_retrained-acc_init)*100:.2f}%p")
    print("="*60)

    # ë¦¬í¬íŠ¸ ë° ì‹œê°í™” (3ê°œ ëª¨ë¸)
    class_names = ['angry', 'happy', 'relaxed', 'sad']
    print_reports(y_true_init, y_pred_init, y_true_orig, y_pred_orig, y_true_retrained, y_pred_retrained, class_names)
    plot_accuracy_compare(acc_init, acc_orig, acc_retrained)
    plot_per_class_f1(y_true_init, y_pred_init, y_true_orig, y_pred_orig, y_true_retrained, y_pred_retrained, class_names)
    plot_confusion_matrices(y_true_init, y_pred_init, y_true_orig, y_pred_orig, y_true_retrained, y_pred_retrained, class_names)


if __name__ == "__main__":
    main()


