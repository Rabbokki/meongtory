"""
ê°•ì•„ì§€ ê°ì • ë°ì´í„°ì…‹ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ë°ì´í„° êµ¬ì¡°, í´ë˜ìŠ¤ ë¶„í¬, ì´ë¯¸ì§€ í’ˆì§ˆ ë“±ì„ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from pathlib import Path
import pandas as pd
from collections import Counter
import warnings
import logging
warnings.filterwarnings('ignore')

# matplotlib í°íŠ¸ ê´€ë ¨ ë¡œê¹… ì–µì œ
logging.getLogger('matplotlib.font_manager').setLevel(logging.WARNING)

class DogEmotionDataAnalyzer:
    def __init__(self, dataset_path):
        """
        ë°ì´í„°ì…‹ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            dataset_path (str): ë°ì´í„°ì…‹ ê²½ë¡œ
        """
        self.dataset_path = Path(dataset_path)
        
        # ì‹¤ì œ ë°ì´í„° í´ë” ì°¾ê¸°
        self.find_actual_data_path()
        
        self.emotions = ['angry', 'happy', 'relaxed', 'sad']
        self.data_info = {}
    
    def find_actual_data_path(self):
        """
        ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ë¡œë¥¼ ì°¾ê³  ë°ì´í„°ì…‹ êµ¬ì¡°ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
        """
        # í•˜ìœ„ í´ë”ë“¤ê³¼ íŒŒì¼ë“¤ í™•ì¸
        subdirs = [d for d in self.dataset_path.iterdir() if d.is_dir()]
        files = [f for f in self.dataset_path.iterdir() if f.is_file()]
        
        print(f"ğŸ“ ìµœìƒìœ„ ë””ë ‰í† ë¦¬ ë‚´ìš©:")
        for subdir in subdirs:
            print(f"   ğŸ“‚ {subdir.name}/")
        for file in files:
            print(f"   ğŸ“„ {file.name}")
        
        # "Dog Emotion" í´ë”ê°€ ìˆë‹¤ë©´ ê·¸ ì•ˆì„ í™•ì¸
        for subdir in subdirs:
            if "emotion" in subdir.name.lower():
                emotion_subdir = subdir
                print(f"\nğŸ” '{subdir.name}' í´ë”ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë‚´ë¶€ êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤...")
                
                # ì´ í´ë” ì•ˆì˜ ëª¨ë“  ë‚´ìš© í™•ì¸
                emotion_subdirs = [d for d in emotion_subdir.iterdir() if d.is_dir()]
                emotion_files = [f for f in emotion_subdir.iterdir() if f.is_file()]
                
                print(f"ğŸ“‚ '{subdir.name}' ë‚´ë¶€ í´ë”ë“¤:")
                for folder in emotion_subdirs:
                    print(f"   - {folder.name}/")
                
                print(f"ğŸ“„ '{subdir.name}' ë‚´ë¶€ íŒŒì¼ë“¤:")
                for file in emotion_files:
                    print(f"   - {file.name}")
                
                # labels.csv íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
                labels_csv = emotion_subdir / "labels.csv"
                if labels_csv.exists():
                    print(f"âœ… labels.csv íŒŒì¼ì„ ë°œê²¬! CSV ë¼ë²¨ë§ ë°©ì‹ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.")
                    self.csv_labels_path = labels_csv
                    self.dataset_type = "csv_labeling"
                    self.dataset_path = emotion_subdir
                    self.analyze_csv_labels()
                    return
                
                # ê°ì • ê´€ë ¨ í´ë”ê°€ ìˆìœ¼ë©´ í´ë” êµ¬ì¡° ë°©ì‹
                emotion_folder_names = [f.name.lower() for f in emotion_subdirs]
                if any(emotion in emotion_folder_names for emotion in self.emotions):
                    print(f"âœ… ê°ì • í´ë”ë“¤ì„ ë°œê²¬! í´ë” êµ¬ì¡° ë°©ì‹ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.")
                    self.dataset_type = "folder_structure"
                    self.dataset_path = emotion_subdir
                    return
    
    def analyze_csv_labels(self):
        """
        CSV ë¼ë²¨ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        try:
            df = pd.read_csv(self.csv_labels_path)
            print(f"\nğŸ“Š CSV ë¼ë²¨ íŒŒì¼ ë¶„ì„:")
            print(f"   - ì´ ë ˆì½”ë“œ ìˆ˜: {len(df)}")
            print(f"   - ì»¬ëŸ¼ëª…: {list(df.columns)}")
            print(f"   - ì²˜ìŒ 5í–‰:")
            print(df.head().to_string(index=False))
            
            # ê°ì • ë¶„í¬ í™•ì¸ (ì»¬ëŸ¼ëª…ì´ 'label'ì¸ ê²½ìš° ê³ ë ¤)
            label_column = None
            if 'emotion' in df.columns:
                label_column = 'emotion'
            elif 'label' in df.columns:
                label_column = 'label'
            
            if label_column:
                emotion_counts = df[label_column].value_counts()
                print(f"\nğŸ­ CSV íŒŒì¼ì˜ ê°ì • ë¶„í¬:")
                for emotion, count in emotion_counts.items():
                    print(f"   - {emotion}: {count}ê°œ")
                    
                self.csv_emotion_counts = emotion_counts.to_dict()
                print(f"âœ… csv_emotion_counts ì €ì¥ ì™„ë£Œ: {self.csv_emotion_counts}")
            else:
                print("âŒ ê°ì • ë¼ë²¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âŒ CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        
    def analyze_dataset_structure(self):
        """
        ë°ì´í„°ì…‹ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        print("ğŸ” ë°ì´í„°ì…‹ êµ¬ì¡° ë¶„ì„")
        print("=" * 50)
        
        # ì „ì²´ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸
        print(f"ğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ: {self.dataset_path}")
        
        # í•˜ìœ„ í´ë”ë“¤ í™•ì¸
        subdirs = [d for d in self.dataset_path.iterdir() if d.is_dir()]
        print(f"ğŸ“‚ í•˜ìœ„ í´ë” ìˆ˜: {len(subdirs)}")
        
        for subdir in subdirs:
            print(f"   - {subdir.name}/")
        
        return subdirs
    
    def analyze_class_distribution(self):
        """
        ê° ê°ì •ë³„ ì´ë¯¸ì§€ ê°œìˆ˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        print("\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„")
        print("=" * 50)
        
        emotion_counts = {}
        total_images = 0
        
        # CSV ë¼ë²¨ë§ ë°©ì‹ì¸ ê²½ìš° CSV íŒŒì¼ì—ì„œ ì¹´ìš´íŠ¸
        if hasattr(self, 'dataset_type') and self.dataset_type == "csv_labeling":
            if hasattr(self, 'csv_emotion_counts') and self.csv_emotion_counts:
                emotion_counts = self.csv_emotion_counts.copy()
                total_images = sum(emotion_counts.values())
                
                print("ğŸ“„ CSV ë¼ë²¨ íŒŒì¼ ê¸°ë°˜ ë¶„í¬:")
                for emotion in self.emotions:
                    count = emotion_counts.get(emotion, 0)
                    print(f"ğŸ˜Š {emotion:>8}: {count:>5}ê°œ")
            else:
                print("âŒ CSV ë¼ë²¨ ë°ì´í„°ë¥¼ ë¨¼ì € ë¶„ì„í•´ì£¼ì„¸ìš”.")
                print(f"Debug: dataset_type={getattr(self, 'dataset_type', 'None')}")
                print(f"Debug: csv_emotion_counts={getattr(self, 'csv_emotion_counts', 'None')}")
                return {}
        else:
            # í´ë” êµ¬ì¡° ë°©ì‹ì¸ ê²½ìš° í´ë”ë³„ ì¹´ìš´íŠ¸
            for emotion in self.emotions:
                emotion_path = self.dataset_path / emotion
                
                if emotion_path.exists():
                    # ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì¹´ìš´íŠ¸ (ì¤‘ë³µ ì œê±°)
                    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
                    image_files = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ set ì‚¬ìš©
                    
                    for ext in image_extensions:
                        image_files.update(emotion_path.glob(f"*{ext}"))
                        image_files.update(emotion_path.glob(f"*{ext.upper()}"))
                    
                    count = len(image_files)
                    emotion_counts[emotion] = count
                    total_images += count
                    
                    print(f"ğŸ˜Š {emotion:>8}: {count:>5}ê°œ")
                else:
                    emotion_counts[emotion] = 0
                    print(f"âŒ {emotion:>8}: í´ë” ì—†ìŒ")
        
        print(f"\nğŸ“ˆ ì´ ì´ë¯¸ì§€ ìˆ˜: {total_images}ê°œ")
        
        # í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„
        if total_images > 0:
            print("\nâš–ï¸  í´ë˜ìŠ¤ ë¶„í¬ ë¹„ìœ¨:")
            for emotion, count in emotion_counts.items():
                percentage = (count / total_images) * 100
                print(f"   {emotion:>8}: {percentage:>5.1f}%")
            
            # ë¶ˆê· í˜• ì •ë„ ê³„ì‚°
            max_count = max(emotion_counts.values())
            min_count = min([c for c in emotion_counts.values() if c > 0])
            
            if min_count > 0:
                imbalance_ratio = max_count / min_count
                print(f"\nğŸ¯ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨: {imbalance_ratio:.2f}:1")
                
                if imbalance_ratio > 2.0:
                    print("âš ï¸  ì‹¬í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜• ê°ì§€! ê°€ì¤‘ì¹˜ ì ìš© ë˜ëŠ” ì˜¤ë²„ìƒ˜í”Œë§ í•„ìš”")
                elif imbalance_ratio > 1.5:
                    print("âš ï¸  ì¤‘ê°„ ì •ë„ í´ë˜ìŠ¤ ë¶ˆê· í˜• ê°ì§€! ê°€ì¤‘ì¹˜ ì ìš© ê¶Œì¥")
                else:
                    print("âœ… í´ë˜ìŠ¤ ë¶„í¬ê°€ ë¹„êµì  ê· í˜•ì ì…ë‹ˆë‹¤")
        
        self.data_info['emotion_counts'] = emotion_counts
        self.data_info['total_images'] = total_images
        
        return emotion_counts
    
    def analyze_image_properties(self, sample_size=100):
        """
        ì´ë¯¸ì§€ ì†ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤ (í¬ê¸°, ì±„ë„, í¬ë§· ë“±).
        
        Args:
            sample_size (int): ë¶„ì„í•  ìƒ˜í”Œ ì´ë¯¸ì§€ ìˆ˜
        """
        print(f"\nğŸ–¼ï¸  ì´ë¯¸ì§€ ì†ì„± ë¶„ì„ (ìƒ˜í”Œ {sample_size}ê°œ)")
        print("=" * 50)
        
        image_info = {
            'widths': [],
            'heights': [],
            'channels': [],
            'formats': [],
            'file_sizes': []
        }
        
        corrupted_files = []
        
        # ê° ê°ì •ë³„ë¡œ ìƒ˜í”Œ ì´ë¯¸ì§€ ë¶„ì„
        for emotion in self.emotions:
            emotion_path = self.dataset_path / emotion
            
            if not emotion_path.exists():
                continue
                
            # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
            image_files = []
            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
            
            for ext in image_extensions:
                image_files.extend(list(emotion_path.glob(f"*{ext}")))
                image_files.extend(list(emotion_path.glob(f"*{ext.upper()}")))
            
            # ìƒ˜í”Œë§
            sample_count = min(sample_size // len(self.emotions), len(image_files))
            sampled_files = np.random.choice(image_files, size=sample_count, replace=False)
            
            for img_path in sampled_files:
                try:
                    with Image.open(img_path) as img:
                        width, height = img.size
                        channels = len(img.getbands())
                        file_format = img.format
                        file_size = img_path.stat().st_size
                        
                        image_info['widths'].append(width)
                        image_info['heights'].append(height)
                        image_info['channels'].append(channels)
                        image_info['formats'].append(file_format)
                        image_info['file_sizes'].append(file_size)
                        
                except Exception as e:
                    corrupted_files.append(str(img_path))
                    print(f"âŒ ì†ìƒëœ íŒŒì¼: {img_path.name} - {str(e)}")
        
        # í†µê³„ ì¶œë ¥
        if image_info['widths']:
            print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°:")
            print(f"   ë„ˆë¹„: {np.min(image_info['widths'])} ~ {np.max(image_info['widths'])} (í‰ê· : {np.mean(image_info['widths']):.1f})")
            print(f"   ë†’ì´: {np.min(image_info['heights'])} ~ {np.max(image_info['heights'])} (í‰ê· : {np.mean(image_info['heights']):.1f})")
            
            print(f"\nğŸ¨ ì±„ë„ ìˆ˜:")
            channel_counts = Counter(image_info['channels'])
            for channels, count in channel_counts.items():
                print(f"   {channels}ì±„ë„: {count}ê°œ")
            
            print(f"\nğŸ“ íŒŒì¼ í¬ë§·:")
            format_counts = Counter(image_info['formats'])
            for fmt, count in format_counts.items():
                print(f"   {fmt}: {count}ê°œ")
            
            print(f"\nğŸ’¾ íŒŒì¼ í¬ê¸°:")
            avg_size = np.mean(image_info['file_sizes']) / 1024  # KB
            print(f"   í‰ê· : {avg_size:.1f} KB")
            print(f"   ë²”ìœ„: {np.min(image_info['file_sizes'])/1024:.1f} ~ {np.max(image_info['file_sizes'])/1024:.1f} KB")
        
        print(f"\nğŸ” í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼:")
        print(f"   ë¶„ì„ëœ ì´ë¯¸ì§€: {len(image_info['widths'])}ê°œ")
        print(f"   ì†ìƒëœ íŒŒì¼: {len(corrupted_files)}ê°œ")
        
        if corrupted_files:
            print("âš ï¸  ì†ìƒëœ íŒŒì¼ë“¤:")
            for file in corrupted_files[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                print(f"     - {file}")
            if len(corrupted_files) > 5:
                print(f"     ... ì™¸ {len(corrupted_files) - 5}ê°œ")
        
        self.data_info['image_properties'] = image_info
        self.data_info['corrupted_files'] = corrupted_files
        
        return image_info, corrupted_files
    
    def suggest_data_split(self):
        """
        Train/Validation/Test ë¶„í• ì„ ì œì•ˆí•©ë‹ˆë‹¤.
        """
        print(f"\nğŸ“‹ ë°ì´í„° ë¶„í•  ì œì•ˆ")
        print("=" * 50)
        
        if 'emotion_counts' not in self.data_info:
            print("âŒ ë¨¼ì € í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.")
            return
        
        total_images = self.data_info['total_images']
        emotion_counts = self.data_info['emotion_counts']
        
        # 70:15:15 ë¶„í• 
        train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15
        
        print(f"ğŸ’¡ ì œì•ˆí•˜ëŠ” ë¶„í•  ë¹„ìœ¨: Train {train_ratio*100:.0f}% / Validation {val_ratio*100:.0f}% / Test {test_ratio*100:.0f}%")
        print()
        
        split_suggestion = {}
        
        for emotion, count in emotion_counts.items():
            if count == 0:
                continue
                
            train_count = int(count * train_ratio)
            val_count = int(count * val_ratio)
            test_count = count - train_count - val_count
            
            split_suggestion[emotion] = {
                'train': train_count,
                'val': val_count,
                'test': test_count
            }
            
            print(f"ğŸ˜Š {emotion:>8}: Train {train_count:>3} | Val {val_count:>3} | Test {test_count:>3}")
        
        # ì´í•© ê³„ì‚°
        total_train = sum([split['train'] for split in split_suggestion.values()])
        total_val = sum([split['val'] for split in split_suggestion.values()])
        total_test = sum([split['test'] for split in split_suggestion.values()])
        
        print(f"\nğŸ“Š ì´ê³„: Train {total_train} | Val {total_val} | Test {total_test}")
        print(f"ğŸ’¯ ë¹„ìœ¨: Train {total_train/total_images*100:.1f}% | Val {total_val/total_images*100:.1f}% | Test {total_test/total_images*100:.1f}%")
        
        self.data_info['split_suggestion'] = split_suggestion
        
        return split_suggestion
    
    def create_visualization(self, save_path=None):
        """
        ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
        
        Args:
            save_path (str): ì €ì¥í•  ê²½ë¡œ (Noneì´ë©´ í™”ë©´ì—ë§Œ í‘œì‹œ)
        """
        if 'emotion_counts' not in self.data_info:
            print("âŒ ë¨¼ì € ë°ì´í„° ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •
        plt.style.use('default')
        sns.set_palette("husl")
        
        # í•œê¸€ í°íŠ¸ ì„¤ì • (Windowsìš©)
        try:
            # Windowsì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ë“¤
            available_fonts = ['Malgun Gothic', 'Microsoft YaHei', 'DejaVu Sans', 'Arial']
            plt.rcParams['font.family'] = available_fonts
            plt.rcParams['axes.unicode_minus'] = False
        except:
            # í°íŠ¸ ì„¤ì • ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            pass
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Dog Emotion Dataset Analysis Results', fontsize=16, fontweight='bold')
        
        # 1. í´ë˜ìŠ¤ ë¶„í¬ ë§‰ëŒ€ ê·¸ë˜í”„
        emotions = list(self.data_info['emotion_counts'].keys())
        counts = list(self.data_info['emotion_counts'].values())
        
        ax1 = axes[0, 0]
        bars = ax1.bar(emotions, counts, color=['#ff6b6b', '#4ecdc4', '#45b7d1', '#f9ca24'])
        ax1.set_title('Class Distribution (Image Count)', fontweight='bold')
        ax1.set_ylabel('Number of Images')
        
        # ë§‰ëŒ€ ìœ„ì— ìˆ«ì í‘œì‹œ
        for bar, count in zip(bars, counts):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, 
                    str(count), ha='center', va='bottom', fontweight='bold')
        
        # 2. í´ë˜ìŠ¤ ë¶„í¬ íŒŒì´ ì°¨íŠ¸
        ax2 = axes[0, 1]
        ax2.pie(counts, labels=emotions, autopct='%1.1f%%', startangle=90,
                colors=['#ff6b6b', '#4ecdc4', '#45b7d1', '#f9ca24'])
        ax2.set_title('Class Distribution Ratio', fontweight='bold')
        
        # 3. ì´ë¯¸ì§€ í¬ê¸° ë¶„í¬ (ìˆëŠ” ê²½ìš°)
        ax3 = axes[1, 0]
        if 'image_properties' in self.data_info and self.data_info['image_properties']['widths']:
            widths = self.data_info['image_properties']['widths']
            heights = self.data_info['image_properties']['heights']
            
            ax3.scatter(widths, heights, alpha=0.6, color='#6c5ce7')
            ax3.set_xlabel('Width (pixels)')
            ax3.set_ylabel('Height (pixels)')
            ax3.set_title('Image Size Distribution', fontweight='bold')
            ax3.grid(True, alpha=0.3)
        else:
            ax3.text(0.5, 0.5, 'Image property\nanalysis needed', 
                    ha='center', va='center', transform=ax3.transAxes, fontsize=12)
            ax3.set_title('Image Size Distribution', fontweight='bold')
        
        # 4. ë°ì´í„° ë¶„í•  ì œì•ˆ (ìˆëŠ” ê²½ìš°)
        ax4 = axes[1, 1]
        if 'split_suggestion' in self.data_info:
            split_data = self.data_info['split_suggestion']
            emotions = list(split_data.keys())
            train_counts = [split_data[emotion]['train'] for emotion in emotions]
            val_counts = [split_data[emotion]['val'] for emotion in emotions]
            test_counts = [split_data[emotion]['test'] for emotion in emotions]
            
            x = np.arange(len(emotions))
            width = 0.25
            
            ax4.bar(x - width, train_counts, width, label='Train', color='#00b894')
            ax4.bar(x, val_counts, width, label='Validation', color='#fdcb6e')
            ax4.bar(x + width, test_counts, width, label='Test', color='#e17055')
            
            ax4.set_xlabel('Emotion')
            ax4.set_ylabel('Number of Images')
            ax4.set_title('Data Split Suggestion', fontweight='bold')
            ax4.set_xticks(x)
            ax4.set_xticklabels(emotions)
            ax4.legend()
        else:
            ax4.text(0.5, 0.5, 'Data split suggestion\nneeded', 
                    ha='center', va='center', transform=ax4.transAxes, fontsize=12)
            ax4.set_title('Data Split Suggestion', fontweight='bold')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ì‹œê°í™” ê²°ê³¼ê°€ {save_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        plt.show()
    
    def generate_report(self):
        """
        ë¶„ì„ ê²°ê³¼ ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        """
        print(f"\nğŸ“‹ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
        print("=" * 50)
        
        if not self.data_info:
            print("âŒ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        print(f"ğŸ¯ ë°ì´í„°ì…‹ ê°œìš”:")
        print(f"   - ì´ ì´ë¯¸ì§€ ìˆ˜: {self.data_info.get('total_images', 0):,}ê°œ")
        print(f"   - ê°ì • í´ë˜ìŠ¤ ìˆ˜: {len(self.emotions)}ê°œ")
        
        if 'corrupted_files' in self.data_info:
            print(f"   - ì†ìƒëœ íŒŒì¼: {len(self.data_info['corrupted_files'])}ê°œ")
        
        print(f"\nğŸ’¡ í•™ìŠµ ê¶Œì¥ì‚¬í•­:")
        
        # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²´í¬
        if 'emotion_counts' in self.data_info:
            counts = list(self.data_info['emotion_counts'].values())
            if max(counts) / min([c for c in counts if c > 0]) > 2.0:
                print("   - âš ï¸  í´ë˜ìŠ¤ ë¶ˆê· í˜•ìœ¼ë¡œ ì¸í•œ ê°€ì¤‘ì¹˜ ì ìš© í•„ìš”")
            else:
                print("   - âœ… í´ë˜ìŠ¤ ë¶„í¬ê°€ ë¹„êµì  ê· í˜•ì ")
        
        # ì´ë¯¸ì§€ í¬ê¸° ê¶Œì¥ì‚¬í•­
        if 'image_properties' in self.data_info:
            widths = self.data_info['image_properties']['widths']
            heights = self.data_info['image_properties']['heights']
            
            if widths and heights:
                avg_width = np.mean(widths)
                avg_height = np.mean(heights)
                
                if avg_width < 224 or avg_height < 224:
                    print("   - âš ï¸  ì¼ë¶€ ì´ë¯¸ì§€ê°€ ì‘ìŒ. ì—…ìŠ¤ì¼€ì¼ë§ ê³ ë ¤ í•„ìš”")
                else:
                    print("   - âœ… ì´ë¯¸ì§€ í¬ê¸°ê°€ ì ì ˆí•¨")
        
        print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
        print("   1. ë°ì´í„° ë¶„í•  ì‹¤í–‰ (train/val/test)")
        print("   2. PyTorch Dataset í´ë˜ìŠ¤ êµ¬í˜„")
        print("   3. Data Augmentation ì„¤ì •")
        print("   4. ëª¨ë¸ í•™ìŠµ ì‹œì‘")

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    # ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì • (ë‹¤ìš´ë¡œë“œëœ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”)
    import kagglehub
    
    try:
        # ìºì‹œëœ ë°ì´í„°ì…‹ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        dataset_path = kagglehub.dataset_download("danielshanbalico/dog-emotion")
        print(f"ğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ: {dataset_path}")
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("download_dataset.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = DogEmotionDataAnalyzer(dataset_path)
    
    print("ğŸš€ ê°•ì•„ì§€ ê°ì • ë°ì´í„°ì…‹ ë¶„ì„ ì‹œì‘!")
    print("=" * 50)
    
    # 1. ë°ì´í„°ì…‹ êµ¬ì¡° ë¶„ì„
    analyzer.analyze_dataset_structure()
    
    # 2. í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
    analyzer.analyze_class_distribution()
    
    # 3. ì´ë¯¸ì§€ ì†ì„± ë¶„ì„
    analyzer.analyze_image_properties(sample_size=200)
    
    # 4. ë°ì´í„° ë¶„í•  ì œì•ˆ
    analyzer.suggest_data_split()
    
    # 5. ì‹œê°í™” ìƒì„±
    try:
        analyzer.create_visualization(save_path="dog_emotion_analysis.png")
    except Exception as e:
        print(f"âš ï¸  ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        print("matplotlibì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”: pip install matplotlib seaborn")
    
    # 6. ì¢…í•© ë¦¬í¬íŠ¸
    analyzer.generate_report()
    
    print(f"\nğŸ‰ ë°ì´í„° ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()