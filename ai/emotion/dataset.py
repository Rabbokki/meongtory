"""
ê°•ì•„ì§€ ê°ì • ë°ì´í„°ì…‹ì„ ìœ„í•œ PyTorch Dataset ë° DataLoader
CSV ë¼ë²¨ë§ ë°©ì‹ì˜ ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from PIL import Image
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
import warnings
import sys
import io

# Windows ì½˜ì†”ì—ì„œ í•œê¸€ ì¶œë ¥ (ê¸°ë³¸ ì¸ì½”ë”© ì‚¬ìš©)

warnings.filterwarnings('ignore')

class DogEmotionDataset(Dataset):
    """
    ê°•ì•„ì§€ ê°ì • ë°ì´í„°ì…‹ì„ ìœ„í•œ PyTorch Dataset í´ë˜ìŠ¤
    """
    
    def __init__(self, csv_file, root_dir, transform=None, emotion_to_idx=None):
        """
        Args:
            csv_file (str): ë¼ë²¨ CSV íŒŒì¼ ê²½ë¡œ
            root_dir (str): ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ìˆëŠ” ë£¨íŠ¸ ë””ë ‰í† ë¦¬
            transform (callable, optional): ì´ë¯¸ì§€ì— ì ìš©í•  ë³€í™˜
            emotion_to_idx (dict): ê°ì • ë¼ë²¨ì„ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
        """
        # CSV íŒŒì¼ ì½ê¸°
        if isinstance(csv_file, str):
            self.labels_df = pd.read_csv(csv_file)
        else:
            self.labels_df = csv_file  # DataFrameì´ ì§ì ‘ ì „ë‹¬ëœ ê²½ìš°
        
        self.root_dir = Path(root_dir)
        self.transform = transform
        
        # ë¼ë²¨ ì»¬ëŸ¼ ì°¾ê¸°
        self.label_column = self._find_label_column()
        
        # ê°ì • ë¼ë²¨ì„ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        if emotion_to_idx is None:
            unique_emotions = self.labels_df[self.label_column].unique()
            self.emotion_to_idx = {emotion: idx for idx, emotion in enumerate(sorted(unique_emotions))}
        else:
            self.emotion_to_idx = emotion_to_idx
        
        self.idx_to_emotion = {idx: emotion for emotion, idx in self.emotion_to_idx.items()}
        
        print(f"ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
        print(f"   - ì´ ìƒ˜í”Œ ìˆ˜: {len(self.labels_df)}")
        print(f"   - ê°ì • í´ë˜ìŠ¤: {list(self.emotion_to_idx.keys())}")
        print(f"   - í´ë˜ìŠ¤ ë§¤í•‘: {self.emotion_to_idx}")
    
    def _find_label_column(self):
        """ë¼ë²¨ ì»¬ëŸ¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
        possible_columns = ['label', 'emotion', 'class', 'target']
        for col in possible_columns:
            if col in self.labels_df.columns:
                return col
        raise ValueError(f"ë¼ë²¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(self.labels_df.columns)}")
    
    def __len__(self):
        return len(self.labels_df)
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        
        # íŒŒì¼ëª…ê³¼ ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°
        row = self.labels_df.iloc[idx]
        filename = row['filename']
        emotion_label = row[self.label_column]
        
        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ êµ¬ì„±
        img_path = self.root_dir / filename
        
        # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ê°ì •ë³„ í´ë”ì—ì„œ ì°¾ê¸°
        if not img_path.exists():
            img_path = self.root_dir / emotion_label / filename
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path} - {e}")
            # ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± (ì—ëŸ¬ ë°©ì§€ìš©)
            image = Image.new('RGB', (224, 224), color='gray')
        
        # ë¼ë²¨ì„ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        label_idx = self.emotion_to_idx[emotion_label]
        
        # ë³€í™˜ ì ìš©
        if self.transform:
            image = self.transform(image)
        
        return image, label_idx, filename
    
    def get_class_weights(self):
        """
        í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        label_counts = self.labels_df[self.label_column].value_counts()
        total_samples = len(self.labels_df)
        
        # ê° í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚°
        class_weights = []
        for emotion in sorted(self.emotion_to_idx.keys()):
            weight = total_samples / (len(self.emotion_to_idx) * label_counts.get(emotion, 1))
            class_weights.append(weight)
        
        return torch.FloatTensor(class_weights)

class DataTransforms:
    """
    ë°ì´í„° ì¦ê°• ë° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤
    """
    
    @staticmethod
    def get_train_transforms(image_size=224):
        """
        í›ˆë ¨ìš© ë°ì´í„° ë³€í™˜ (Data Augmentation í¬í•¨)
        """
        return transforms.Compose([
            transforms.Resize((image_size + 32, image_size + 32)),  # ì—¬ìœ ë¶„ì„ ë‘” ë¦¬ì‚¬ì´ì¦ˆ
            transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),  # ëœë¤ í¬ë¡­
            transforms.RandomHorizontalFlip(p=0.5),  # ì¢Œìš° ë°˜ì „
            transforms.ColorJitter(
                brightness=0.2,      # ë°ê¸° ë³€í™”
                contrast=0.2,        # ëŒ€ë¹„ ë³€í™”  
                saturation=0.2,      # ì±„ë„ ë³€í™”
                hue=0.1             # ìƒ‰ì¡° ë³€í™”
            ),
            transforms.RandomRotation(degrees=15),  # 15ë„ ë²”ìœ„ ë‚´ íšŒì „
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],  # ImageNet í‰ê· 
                std=[0.229, 0.224, 0.225]    # ImageNet í‘œì¤€í¸ì°¨
            )
        ])
    
    @staticmethod
    def get_val_transforms(image_size=224):
        """
        ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ë³€í™˜ (Augmentation ì—†ìŒ)
        """
        return transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

class DataSplitter:
    """
    ë°ì´í„°ë¥¼ Train/Validation/Testë¡œ ë¶„í• í•˜ëŠ” í´ë˜ìŠ¤
    """
    
    def __init__(self, csv_file, root_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42):
        """
        Args:
            csv_file (str): ë¼ë²¨ CSV íŒŒì¼ ê²½ë¡œ
            root_dir (str): ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            train_ratio (float): í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨
            val_ratio (float): ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
            test_ratio (float): í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
            random_state (int): ëœë¤ ì‹œë“œ
        """
        self.df = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.train_ratio = train_ratio
        self.val_ratio = val_ratio
        self.test_ratio = test_ratio
        self.random_state = random_state
        
        # ë¹„ìœ¨ ê²€ì¦
        if abs(train_ratio + val_ratio + test_ratio - 1.0) > 1e-6:
            raise ValueError(f"ë¹„ìœ¨ì˜ í•©ì´ 1.0ì´ ì•„ë‹™ë‹ˆë‹¤: {train_ratio + val_ratio + test_ratio}")
        
        # ë¼ë²¨ ì»¬ëŸ¼ ì°¾ê¸°
        self.label_column = self._find_label_column()
        
    def _find_label_column(self):
        """ë¼ë²¨ ì»¬ëŸ¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
        possible_columns = ['label', 'emotion', 'class', 'target']
        for col in possible_columns:
            if col in self.df.columns:
                return col
        raise ValueError(f"ë¼ë²¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def split_data(self):
        """
        ë°ì´í„°ë¥¼ ê³„ì¸µí™” ìƒ˜í”Œë§ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
        
        Returns:
            tuple: (train_df, val_df, test_df)
        """
        print("ğŸ“‹ ë°ì´í„° ë¶„í•  ì‹œì‘...")
        
        # ê³„ì¸µí™” ìƒ˜í”Œë§ìœ¼ë¡œ trainê³¼ ë‚˜ë¨¸ì§€ë¡œ ë¶„í• 
        train_df, temp_df = train_test_split(
            self.df,
            test_size=(1 - self.train_ratio),
            stratify=self.df[self.label_column],
            random_state=self.random_state
        )
        
        # ë‚˜ë¨¸ì§€ë¥¼ validationê³¼ testë¡œ ë¶„í• 
        val_size = self.val_ratio / (self.val_ratio + self.test_ratio)
        val_df, test_df = train_test_split(
            temp_df,
            test_size=(1 - val_size),
            stratify=temp_df[self.label_column],
            random_state=self.random_state
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
        print(f"   ğŸ“š í›ˆë ¨ ë°ì´í„°: {len(train_df)}ê°œ ({len(train_df)/len(self.df)*100:.1f}%)")
        print(f"   ğŸ“Š ê²€ì¦ ë°ì´í„°: {len(val_df)}ê°œ ({len(val_df)/len(self.df)*100:.1f}%)")
        print(f"   ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ê°œ ({len(test_df)/len(self.df)*100:.1f}%)")
        
        # ê° ë¶„í• ì˜ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
        self._print_class_distribution(train_df, "í›ˆë ¨")
        self._print_class_distribution(val_df, "ê²€ì¦")
        self._print_class_distribution(test_df, "í…ŒìŠ¤íŠ¸")
        
        return train_df, val_df, test_df
    
    def _print_class_distribution(self, df, set_name):
        """ê° ì„¸íŠ¸ì˜ í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
        class_counts = df[self.label_column].value_counts()
        print(f"\nğŸ­ {set_name} ì„¸íŠ¸ í´ë˜ìŠ¤ ë¶„í¬:")
        for emotion, count in class_counts.items():
            percentage = count / len(df) * 100
            print(f"   - {emotion}: {count}ê°œ ({percentage:.1f}%)")

def create_data_loaders(csv_file, root_dir, batch_size=32, num_workers=4, image_size=224, 
                       train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):
    """
    Train/Val/Test DataLoaderë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        csv_file (str): ë¼ë²¨ CSV íŒŒì¼ ê²½ë¡œ
        root_dir (str): ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        batch_size (int): ë°°ì¹˜ í¬ê¸°
        num_workers (int): ë°ì´í„° ë¡œë”© ì›Œì»¤ ìˆ˜
        image_size (int): ì´ë¯¸ì§€ í¬ê¸°
        train_ratio (float): í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨
        val_ratio (float): ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
        test_ratio (float): í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
    
    Returns:
        tuple: (train_loader, val_loader, test_loader, class_weights, emotion_to_idx)
    """
    print("ğŸš€ DataLoader ìƒì„± ì‹œì‘...")
    
    # 1. ë°ì´í„° ë¶„í• 
    splitter = DataSplitter(csv_file, root_dir, train_ratio, val_ratio, test_ratio)
    train_df, val_df, test_df = splitter.split_data()
    
    # 2. ë³€í™˜ ì •ì˜
    train_transform = DataTransforms.get_train_transforms(image_size)
    val_transform = DataTransforms.get_val_transforms(image_size)
    
    # 3. Dataset ìƒì„±
    train_dataset = DogEmotionDataset(train_df, root_dir, train_transform)
    val_dataset = DogEmotionDataset(val_df, root_dir, val_transform, train_dataset.emotion_to_idx)
    test_dataset = DogEmotionDataset(test_df, root_dir, val_transform, train_dataset.emotion_to_idx)
    
    # 4. DataLoader ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,  # GPU ì‚¬ìš© ì‹œ ì„±ëŠ¥ í–¥ìƒ
        drop_last=True    # ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ ì‘ìœ¼ë©´ ì œê±°
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    # 5. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    class_weights = train_dataset.get_class_weights()
    
    print(f"âœ… DataLoader ìƒì„± ì™„ë£Œ!")
    print(f"   ğŸ“š Train ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
    print(f"   ğŸ“Š Val ë°°ì¹˜ ìˆ˜: {len(val_loader)}")
    print(f"   ğŸ§ª Test ë°°ì¹˜ ìˆ˜: {len(test_loader)}")
    print(f"   âš–ï¸  í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights.tolist()}")
    
    return train_loader, val_loader, test_loader, class_weights, train_dataset.emotion_to_idx

def test_dataloader():
    """
    DataLoaderë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
    """
    import kagglehub
    
    try:
        # ë°ì´í„°ì…‹ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        dataset_path = kagglehub.dataset_download("danielshanbalico/dog-emotion")
        dataset_path = Path(dataset_path) / "Dog Emotion"
        csv_file = dataset_path / "labels.csv"
        
        print(f"ğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ: {dataset_path}")
        
        # DataLoader ìƒì„±
        train_loader, val_loader, test_loader, class_weights, emotion_to_idx = create_data_loaders(
            csv_file=csv_file,
            root_dir=dataset_path,
            batch_size=16,  # í…ŒìŠ¤íŠ¸ìš© ì‘ì€ ë°°ì¹˜
            num_workers=2,   # í…ŒìŠ¤íŠ¸ìš© ì ì€ ì›Œì»¤
            image_size=224
        )
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ§ª ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸:")
        train_batch = next(iter(train_loader))
        images, labels, filenames = train_batch
        
        print(f"   - ì´ë¯¸ì§€ í…ì„œ í˜•íƒœ: {images.shape}")
        print(f"   - ë¼ë²¨ í…ì„œ í˜•íƒœ: {labels.shape}")
        print(f"   - ë°°ì¹˜ ë‚´ í´ë˜ìŠ¤ ë¶„í¬: {torch.bincount(labels)}")
        print(f"   - íŒŒì¼ëª… ì˜ˆì‹œ: {filenames[:3]}")
        
        # ì´ë¯¸ì§€ ê°’ ë²”ìœ„ í™•ì¸
        print(f"   - ì´ë¯¸ì§€ ê°’ ë²”ìœ„: [{images.min():.3f}, {images.max():.3f}]")
        
        print(f"\nâœ… DataLoader í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
        return train_loader, val_loader, test_loader, class_weights, emotion_to_idx
        
    except Exception as e:
        print(f"âŒ DataLoader í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    # DataLoader í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    result = test_dataloader()
    
    if result:
        print("\nğŸ‰ DataLoaderê°€ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸš€ ì´ì œ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")